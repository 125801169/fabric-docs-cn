# 排序服务

**受众**：架构师、排序服务管理员、通道创建者

本文将介绍排序的概念、排序节点如何与 Peer 节点交互以及排序节点在交易流程中所扮演的角色，同时还会概述当前可用的排序服务实现方式，其中会着重讲解 **Raft** 排序服务实现。

## 什么是排序？

许多分布式区块链，如以太坊（Ethereum）和比特币（Bitcoin），都是非许可链，这意味着任何节点都可以参与共识过程，其中各交易被排序并捆绑进区块。基于这一事实，这些区块链系统依靠**概率**共识算法来保证账本最终达到最大可能性的一致，但概率共识算法依然有可能出现账本不一致的情况（也叫作账本“分叉”），当出现这种情况时，网络中的不同参与者对于已作出的交易顺序意见不一致。

Hyperledger Fabric 和上述的区块链系统不同。在Hyperledger Fabric 中，一种名为**排序节点**的节点负责交易排序，所有排序节点一起构成**排序服务**。因为 Fabric 的这种设计依赖于**确定性**共识算法，所以任何经 Peer 节点验证的区块都绝对是最终的，也绝对是正确的。上面提到的其他分布式非许可区块链网络出现账本分叉的情况不会发生在Hyperledger Fabric 中。

将链码执行的背书（发生在节点上）与排序分隔开这一做法不仅提升了不可改变性，优化了 Fabric 的性能和可扩展性，同时当相同节点既负责执行又负责排序时可能会出现的那些瓶颈也被成功消除。

## 排序节点和通道配置

排序节点除了负责**排序**之外，还维护着被允许创建通道的组织的列表。此组织列表称为“联盟”，列表本身保存在“排序节点系统通道”（也称为“排序系统通道”）的配置中。默认情况下，此列表及其所在的通道只能由排序节点管理员进行编辑。请注意，排序服务可以保存几个这样的列表，这使得联盟成为 Fabric 多租户的载体。

排序节点还为通道执行基本的访问控制，限制能够在通道上读写数据和能够配置通道的操作者。要记住的是，授权哪个操作者来对通道上的配置部件进行修改这一问题取决于相关管理员在创建联盟或通道时所设定的策略。配置交易由排序节点处理，因为排序节点需要知道当前的策略集合，并根据策略来执行基本的访问控制。在这种情况下，排序节点要处理配置更新，以确保请求者拥有适当的管理权限。如果请求者有权限，排序节点将根据现有配置验证更新请求，生成一个新的配置交易，并将其打包到一个区块中，该区块将被转发给通道上的所有节点。然后节点处理配置交易，以验证排序节点批准的修改确实满足通道中定义的策略。

## 排序节点和身份

任何与区块链网络交互的东西，包括节点、应用程序、管理员和排序节点，都要从各自的数字证书和成员服务提供者（MSP）定义中获取自己的组织身份。

有关身份和 MSP 的更多信息，请查看我们关于[身份](../identity/identity.html)和[成员](../membership/membership.html)的文档。

排序节点和 Peer 节点一样，也属于一个组织。与 Peer 节点相似，排序节点的各组织也需要使用单独的证书授权中心（CA）。至于这个 CA 是否将充当根 CA，或者您是否选择部署一个根 CA，然后将一些中间 CA与此根CA联系起来，这完全取决于您自己。

## 排序节点和交易流程

### 阶段一：提案

从对 [Peer 节点](../peers/peers.html)的讨论中我们已经看到，peer 节点构成了区块链网络的基础，它托管账本，并且应用程序可以通过智能合约查询和更新这些账本。

具体来说，想要更新账本的应用程序都参与到一个分三阶段的流程中，这些阶段确保了区块链网络中的所有节点维持彼此账本一致。

在第一阶段，客户端应用程序把交易提案发送给一组节点，这些节点将调用智能合约来生成提案账本更新，然后对结果进行背书。背书节点此时不会把提案更新应用到自己的账本副本上，而是向客户端应用程序返回一个提案响应。已背书的交易提案最终将在第二阶段被排序进区块中，然后在第三阶段被分发给所有节点进行最终验证和提交。

若要深入了解第一个阶段，请参阅[节点](../peers/peers.html#phase-1-proposal)主题。

### 阶段二：将交易排序并打包到区块中

完成交易的第一阶段之后，客户端应用程序已经从一组节点那里收到一个经过背书的交易提案响应。现在要开始交易的第二阶段。

在这一阶段，应用程序客户端把包含已背书交易提案响应的交易提交给排序服务节点。排序服务生成交易区块，这些交易区块最终将被分发给通道上的所有 Peer 节点，以便在第三阶段进行最终验证和提交。

排序服务节点同时接收来自多个不同应用程序客户端的交易。这些排序服务节点相互协作，共同组成排序服务。排序服务的职责是将一批已提交的交易按照定义明确的次序排列并打包进*区块*。这些区块将变成区块链中的*区块*！

区块中的交易数量取决于跟区块的理想大小和最大间隔时间相关的通道配置参数（确切地说，也就是 `BatchSize` 和 `BatchTimeout` 参数）。随后，这些区块被保存在排序节点的账本中，并被分发给已经加入通道的所有节点。如果此时恰好有一个 Peer 节点关闭，或者有一个节点之后才加入通道，那么它将在重新连接到排序服务节点或与另一个 Peer 节点通信之后接收到这些区块。我们将在第三阶段看到节点如何处理这个区块。

![Orderer1](./orderer.diagram.1.png)

*排序节点的第一个角色是打包提案的账本更新。在本例中，应用程序 A1 向排序节点 O1 发送一个由 E1 和 E2 背书的交易 T1。同时，应用程序 A2 将 E1 背书的交易 T2 发送给排序节点 O1。O1 将交易 T1 和 T2 同网络中其他应用程序发来的交易一起打包到区块 B2 中。我们可以看到，在 B2 中交易的顺序是 T1、T2、T3、T4、T6、T5，但这或许和各交易到达该排序节点的先后顺序不同！（这个例子展示了一个非常简单的排序服务配置，只有一个排序节点。）*

值得注意的是，一个区块中所有交易的顺序和各交易到达排序服务的顺序不一定相同，这是因为可能有多个排序服务节点几乎同时接收到交易。重要的是，排序服务对所有交易严格排序，并且 Peer 节点会按照这一顺序对各项交易进行验证和提交。

在有些区块链网络中，同一交易可被打包进多个不同的区块中，这些区块相互竞争形成一条区块链，而 Hyperledger Fabric 对区块中的交易严格排序，这也使其区别于其他那些区块链网络。在 Hyperledger Fabric 中，由排序服务生成的区块是**最终的**。交易一旦被写进区块，那么它在账本中的位置就绝对不会改变。正如我们前面所说，Hyperledger Fabric 的最终性意味着**账本分叉**不会发生，也就是说，经过验证的交易永远不会被重写或删除。

我们还可以看到，Peer 节点负责执行智能合约并处理交易，而排序节点不会这样做。到达排序节点的每个授权交易都被机械地打包在一个区块中，排序节点不判断交易的内容（前面提到的通道配置交易除外）。

在第二阶段的最后，我们看到排序节点负责一些简单但重要的过程，包括收集已提案的交易更新、排序并将它们打包成区块、准备分发给各peer节点。

### 阶段三：验证和提交

在交易工作流的第三个阶段，排序节点把交易区块分发到各个 Peer 节点上，随后这些 peer 节点对收到的各区块进行验证，并最终将这些区块提交到各自的账本中。

第三阶段最初，排序节点将各区块分发给所有与其相连接的 Peer 节点。同样值得注意的是，并不是每个 Peer 节点都需要连接一个排序节点，Peer 节点可以使用 [**gossip 协议**](../gossip.html)将区块传送给其他未连接给排序服务的 peer 节点。

每个节点独立验证分布式区块，各节点的验证结果都具有决定性影响（任何节点对某个区块的验证结构都会影响其他节点对该区块的最终验证结果），确保了账本的一致性。具体来说，通道中每个节点都将验证区块中的所有交易，以确保各交易已被所需组织的节点背书，确保交易的背书能够匹配，同时还确保各交易未因其他新提交的交易而变为无效，各交易最初受到背书时那些新提交的交易可能正在进行中。无效的交易仍然保留在排序节点创建的区块中，但是节点将它们标记为无效，并且它们不会更新账本的状态。

![Orderer2](./orderer.diagram.2.png)

*排序节点的第二个角色是将区块分发给 Peer 节点。在本例中，排序节点 O1 将区块 B2 分配给节点 P1 和 P2。节点 P1 处理区块 B2，在 P1 上的账本 L1 中添加一个新区块。同时，节点 P2 处理区块 B2，从而将一个新区块添加到 P2 上的账本 L1中。一旦这个过程结束，节点 P1 和 P2 上的账本 L1 就完成了一致更新，并且它们可能都会把交易已处理的信息通知给与之相连的应用程序。*

总之，在第三阶段中，排序节点生成的区块会被一致应用到账本上。交易被严格排序进区块中，这使得各节点可以验证交易更新是否在整个区块链网络上得到一致应用。

要更深入地了解阶段三，请参阅[节点](../peers/peers.html#phase-3-validation-and-commit)主题。

## 排序服务实现

虽然当前可用的每个排序服务都以相同的方式处理交易和配置更新，但是要在排序服务节点之间就严格的交易排序达成共识却存在几种不同的实现方法。

有关如何建立排序节点（无论该节点将在什么实现中使用）的信息，请参阅[关于建立排序节点](../orderer_deploy.html)的文档。

* **Raft**

  Hyperledger Fabric 从版本v1.4.1才开始出现 Raft 排序方式，它是一种基于 [`etcd`](https://coreos.com/etcd/) 中 [Raft 协议](https://raft.github.io/raft.pdf)实现的崩溃容错（Crash Fault Tolerant，CFT）排序服务。Raft 采用“主从”模型，这种模型中，（每个通道上）选举出一个主节点，其决策被复制给从节点。Raft  排序服务比 Kafka 的排序服务更容易设置和管理，并且raft的设计允许不同的组织贡献节点来共同组成分布式排序服务。

* **Kafka**

  和基于 Raft 的排序服务类似，Apache Kafka 是一个 CFT （Crash-fault tolerant 崩溃容错）的实现，它使用“主从”节点配置。Kafka 利用一个 ZooKeeper 进行管理。基于 Kafka 的排序服务从 Fabric v1.0开始就可以使用，但许多用户可能会发现管理 Kafka 集群的额外管理开销令人生畏或不受欢迎。

* **Solo**

  排序服务的 Solo 实现仅用于测试，它只包含一个排序节点。目前它已被弃用，在后续版本中它可能会被完全删除。仍在使用 Solo 的用户应该更换成单节点的 Raft 网络以实现同等功能。

## Solo

如上所述，在开发测试、开发或概念验证网络时，单独排序服务是一个不错的选择。出于这个原因，它是部署在我们[构建第一个网络教程](../build_network.html)中默认的排序服务，从其他网络组件的角度来看， Solo 排序服务处理交易和更复杂的 Kafka 和 Raft 实现相同，同时节省了维护和升级多个节点和集群的管理开销。由于 Solo 排序服务不能容错，因此永远不应该认为它是生产区块链网络的可行替代方案。对于只希望从 Solo 排序节点开始但将来可能希望增长的网络，单节点 Raft 集群是更好的选择。

## Raft

有关如何配置 Raft 排序服务的信息，请参阅有关[配置 Raft 排序服务](../raft_configuration.html)的文档。

对于生产网络的排序服务选择，Fabric 的Raft 协议实现采用了“主从”模型，其中主节点是在一个通道的排序节点中动态选举出来的（这个节点的集合被称为“背书者集合（consenter set）”），主节点将信息复制给从节点。Raft 系统可以承受节点的损失，哪怕是主节点，但前提是要有大多数节点（也就是我们所说的“法定人数”）存活。Raft 是“崩溃容错”（CFT）型的。换句话说，如果一个通道中有三个节点，那么该通道可以承受一个节点的丢失（剩下两个节点）。如果一个通道中有五个节点，则可以丢失两个节点（剩下三个节点）。

从 Raft 和现有的 Kafka 排序服务（我们将在稍后讨论）给网络或通道提供的服务这个角度来看，二者是相似的。它们都是基于CFT模型的排序服务，并且都采用了主从节点的设置。如果您是应用程序开发人员、智能合约开发人员或节点管理员，您或许不会注意到二者之间的功能差异。但是，二者之间存在的几个重要差异值得考虑，特别是如果你打算管理一个排序服务的话：

* Raft 更容易设置。虽然觉得 Kafka 非常好的人很多，但即使这些人也（通常）会承认部署 Kafka 集群及其 ZooKeeper 集群是很棘手的，必须要在 Kafka 基础设施和设置方面拥有高水平的专业知识才行。此外，使用 Kafka 管理的组件比使用 Raft 管理的组件多很多，这意味着可能出现问题的地方更多。Kafka 有自己的版本，必须与您的排序节点协调。**使用 Raft，所有内容都会嵌入到您的排序节点中**。
* Kafka 和 Zookeeper 的设计不适用于大型网络。它们的设计是 CFT 模型，但局限于运行的比较紧密的主机上。也就是说，需要有一个组织专门运行 kafka 集群。鉴于此，当有多个组织使用基于kafka排序服务的时候，其实并没有实现去中心化，因为所有节点连接的都是由一个组织单独控制的kafka集群。
* Raft 是原生支持的。虽然基于 Kafka 的排序服务目前与 Fabric 兼容，但用户需要获得相关的镜像，并学习如何独立使用 Kafka 和 ZooKeeper。同样，对 Kafka 相关问题的支持是通过 [Apache](https://kafka.apache.org/) 来处理的，而不是 Hyperledge Fabric，Apache 是 Kafka 的开源开发者。另一方面，Fabric Raft 的实现已经开发出来了，并将在 Fabric 开发人员社区及其支持设备中得到支持。
* Kafka 使用一个服务器池（称为“Kafka 代理”），排序服务组织的管理员负责指定出在特定通道上要使用多少个节点，而 Raft 允许用户自己指定哪个排序节点要部署到哪个通道。这样一来，节点组织就可以确保：如果它们自己拥有排序节点的话，该节点将会成为所在通道上排序服务的一部分，因此它们也就不用信任、依赖中心化的管理员来管理 Kafka 节点了。
* Raft 是 Fabric 实现拜占庭容错（BFT）排序服务的第一步。正如我们将看到的，Fabric 开发中的一些决策是由这个驱动的。如果你对 BFT 感兴趣的话，学习如何使用 Raft 可以帮助你实现拜占庭容错排序服务。

**注意：与 Solo 和 Kafka 类似，在向客户发送回执后 Raft 排序服务也可能会丢失交易。例如，如果主节点几乎在从节点提供回执的同一时间发生崩溃的话，就有可能出现以上情况。因此，应用程序客户端应该监听节点上的交易提交事件，而不是检查交易的有效性。不过还需要格外注意的是确保客户端可以很轻松地应对交易未在配置时间段内成功提交的超时情况。出现这种情况时，可能需要重新提交交易或者针对超时情况重新收集一组新的背书，具体怎么做取决于应用程序本身。**

### Raft 概念

虽然 Raft 提供了许多与 Kafka 相同的功能（相比之下，Raft 的功能包更简单易用），但二者的运作方式却大不一样，Raft 给 Fabric 引入了许多新的概念，或改变了Fabric 一些现有的概念。

**日志条目（Log entry）**。 Raft 排序服务中的主要工作单元是一个“日志条目”，该项的完整序列称为“日志”。如果大多数成员（换句话说就是法定人数）同意一些条目及其顺序，则我们认为各条目彼此一致，这样就使得日志在所有排序节点上得到复制。

**背书者集合（Consenter set）**。排序节点主动参与给定通道的共识机制并接收该通道的日志副本。这些排序节点可以是所有可用的节点（存在于单个集群中或者存在于为系统通道做贡献的多个集群中），也可以是所有节点的一个子集。

**有限状态机（Finite-State Machine，FSM）**。Raft 中的每个排序节点都有一个 FSM，它们共同用于确保各个排序节点中的日志序列是确定（以相同的顺序编写）。

**法定人数（Quorum）**。交易被排序之前需要有一定数量的背书者确认提案，法定人数描述的就是需要确认提案的最少背书者数量。对于每个背书者集合来说，法定人数就是该集合中的**大多数**节点。如果一个集群中有五个节点，那么至少其中三个节点可用才能形成法定人数。如果构成法定人数的节点因某种原因不可用，则排序服务集群无法用于通道上的读写操作，也无法提交任何新日志。

**主节点（Leader）**。这并不是一个新概念，我们此前也说到，Kafka 也使用主节点，但是在任何给定的时间，通道的背书者集合选择单个节点作为主节点，理解这一点十分关键（我们稍后将在 Raft 中描述这是如何发生的）。主节点负责接收新的日志条目，将它们复制到从节点，并在认为提交了某个条目时进行管理。这不是一种特殊**类型**的排序节点。它只是排序节点在某些时候可能扮演的角色，是否扮演此角色视情况而定。

**从节点（Follower）**。这也不是一个新概念，但要知道的是，从节点接收主节点发来的日志并进行复制，任何从节点的复制结果都是决定性的，这就确保了各日志保持一致，理解这一点十分关键。我们将在关于主节点选举的部分中看到，从节点还会收到来自主节点的“心跳”消息。如果主节点在一段可配置的时间内停止发送这些消息，那么从节点将发起一次选举，它们中的一个将当选为新的主节点。

### 交易流程中的 Raft

每个通道都在 Raft 协议的**单独**实例上运行，Raft 协议允许每个实例选择出一个主节点，各主节点互不相同。有些用户案列中的集群是由受不同组织控制的排序节点组成的，对于这种案例，上述配置还可以实现进一步的去中心化服务。虽然所有 Raft 节点都必须是系统通道的一部分，但它们不一定必须是所有应用程序通道的一部分。通道创建者（和通道管理员）能够挑选可用排序节点的子集，并根据需要添加或删除排序节点（只要每次只添加或删除一个节点即可）。

虽然上述配置中心跳消息和线程这些冗余的形式产生了更多开销，但它为 BFT 奠定了必要的基础。

在 Raft 中，收到交易（以提案或配置更新的形式）的排序节点将此交易自动传送给该通道的当前主节点。这意味着无论何时 Peer 节点和应用程序都不需要知道谁是此时的主节点。只有排序节点需要知道。

当排序节点验证检查完成后，将按照我们交易流程的第二阶段的描述，对交易进行排序、打包成区块、背书并分发。

### 架构说明

#### Raft 是如何选举主节点的

尽管主节点的选举过程发生在排序节点的内部，但还是有必要了解一下这个过程是如何进行的。

Raft 节点总是处于以下三种状态之一：从节点、候选节点或主节点。所有节点最初都是作为**从节点**开始的。在这种状态下，它们可以接受来自主节点的日志条目（如果已选出一个主节点），或者为主节点投票。如果在一段时间内没有接收到日志条目或心跳（例如，5秒），节点将自己提升到**候选节点**状态。处于候选状态时，节点请求其他节点的选票。如果一个候选节点获得多数选票，那么它就被提升为主节点。主节点必须接受新的日志条目并将其复制给从节点。

要了解领导者选举过程的可视化表示，请查看[数据的秘密生活](http://thesecretlivesofdata.com/raft/)。

#### 快照

如果一个排序节点宕机，那么它重新启动后如何获得它丢失的日志呢？

虽然可以无限期地保留所有日志，但是为了节省磁盘空间，Raft 采用一种被称为“快照”的过程，在这个过程中，用户可以定义日志中要保留多少字节的数据。这个数据量将符合一定数量的区块（这取决于区块中的数据量。注意，快照中只存储完整的区块）。

例如，假设滞后副本 `R1` 刚刚重新连接到网络。它最新的区块是`100`。主节点 `L` 的最新区块是 `196` ，并被配置为快照20个区块。`R1` 将从 `L` 那里接收区块`180`，然后发送一个 `Deliver` 请求区块 `101`到 `180` 。紧接着区块 `180` 到 `196`将通过正常 Raft 协议复制到 `R1`。

### Kafka

Fabric 支持的另一个崩溃容错排序服务是对 Kafka 分布式流平台的改写，将其用作排序节点集群。您可以在 [Apache Kafka 网站](https://kafka.apache.org/intro)上阅读更多关于 Kafka 的信息，但是在更高的层次上，Kafka 使用与 Raft 相同概念上的“主从节点”配置，其中交易（Kafka 中称为“消息”）被从主节点复制到从节点。和 Raft 情况一样，当主节点宕机时，从节点中的一个就会成为主节点，排序可以继续，以此来确保容错。

Kafka 集群的管理，包括任务协调、集群成员、访问控制和控制器选择等，是由一个 ZooKeeper 集合及其相关 API （应用程序编程接口）来处理的。

Kafka 集群和 ZooKeeper 集合的设置是出了名的棘手，所以我们的文档假设读者对 Kafka 和 ZooKeeper 有一定的了解。如果您决定在不具备此专业知识的情况下使用 Kafka，那么在试验基于 Kafka 的排序服务之前，至少应该完成 [Kafka 快速入门指南](https://kafka.apache.org/quickstart)的前六个步骤。您还可以参考 [这个示例配置文件](https://github.com/hyperledger/fabric/blob/release-1.1/bddtests/dc-orderer-kafka.yml) ，其中简要解释了 Kafka 和 ZooKeeper 的合理默认值。


要了解如何启动基于 Kafka 的排序服务，请查看我们关于 [Kafka 的文档](../kafka.html)。

<!--- Licensed under Creative Commons Attribution 4.0 International License
https://creativecommons.org/licenses/by/4.0/) -->